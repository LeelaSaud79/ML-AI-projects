{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proprietary content. Â© Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning examples using Keras + Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build first network using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WinPython-64bit-3.5.3.0Qt5\\python-3.5.3.amd64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "(768, 8)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "# Create simple network with Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "print(dataset.shape)\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "print(X.shape)\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WinPython-64bit-3.5.3.0Qt5\\python-3.5.3.amd64\\lib\\site-packages\\ipykernel\\__main__.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, kernel_initializer=\"uniform\", input_dim=8)`\n",
      "C:\\WinPython-64bit-3.5.3.0Qt5\\python-3.5.3.amd64\\lib\\site-packages\\ipykernel\\__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, kernel_initializer=\"uniform\")`\n",
      "C:\\WinPython-64bit-3.5.3.0Qt5\\python-3.5.3.amd64\\lib\\site-packages\\ipykernel\\__main__.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sigmoid_cross_entropy_with_logits() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ecfd8975fe45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[1;31m# Compile model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\WinPython-64bit-3.5.3.0Qt5\\python-3.5.3.amd64\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                            \u001b[0mweighted_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweighted_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                            \u001b[0mtarget_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                            **kwargs)\n\u001b[0m\u001b[1;32m    864\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\WinPython-64bit-3.5.3.0Qt5\\python-3.5.3.amd64\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    828\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[0;32m--> 830\u001b[0;31m                                                 sample_weight, mask)\n\u001b[0m\u001b[1;32m    831\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\WinPython-64bit-3.5.3.0Qt5\\python-3.5.3.amd64\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \"\"\"\n\u001b[1;32m    428\u001b[0m         \u001b[1;31m# score_array has ndim >= 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[1;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\WinPython-64bit-3.5.3.0Qt5\\python-3.5.3.amd64\\lib\\site-packages\\keras\\losses.py\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbinary_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\WinPython-64bit-3.5.3.0Qt5\\python-3.5.3.amd64\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[0;34m(target, output, from_logits)\u001b[0m\n\u001b[1;32m   3076\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m     return tf.nn.sigmoid_cross_entropy_with_logits(labels=target,\n\u001b[0;32m-> 3078\u001b[0;31m                                                    logits=output)\n\u001b[0m\u001b[1;32m   3079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sigmoid_cross_entropy_with_logits() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "# create first model\n",
    "model = Sequential()\n",
    "#Adding 3 dense layers\n",
    "model.add(Dense(12, input_dim=8,init='uniform'))\n",
    "model.add(Dense(8,init='uniform'))\n",
    "model.add(Dense(1,init='uniform'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, nb_epoch=20, batch_size=10,  verbose=2)\n",
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "0s - loss: 0.6767 - acc: 0.6107\n",
      "Epoch 2/20\n",
      "0s - loss: 0.6678 - acc: 0.6510\n",
      "Epoch 3/20\n",
      "0s - loss: 0.6607 - acc: 0.6576\n",
      "Epoch 4/20\n",
      "0s - loss: 0.6577 - acc: 0.6549\n",
      "Epoch 5/20\n",
      "0s - loss: 0.6534 - acc: 0.6510\n",
      "Epoch 6/20\n",
      "0s - loss: 0.6501 - acc: 0.6549\n",
      "Epoch 7/20\n",
      "0s - loss: 0.6441 - acc: 0.6602\n",
      "Epoch 8/20\n",
      "0s - loss: 0.6396 - acc: 0.6589\n",
      "Epoch 9/20\n",
      "0s - loss: 0.6334 - acc: 0.6576\n",
      "Epoch 10/20\n",
      "0s - loss: 0.6295 - acc: 0.6680\n",
      "Epoch 11/20\n",
      "0s - loss: 0.6222 - acc: 0.6628\n",
      "Epoch 12/20\n",
      "0s - loss: 0.6190 - acc: 0.6693\n",
      "Epoch 13/20\n",
      "0s - loss: 0.6123 - acc: 0.6784\n",
      "Epoch 14/20\n",
      "0s - loss: 0.6082 - acc: 0.6784\n",
      "Epoch 15/20\n",
      "0s - loss: 0.6023 - acc: 0.6823\n",
      "Epoch 16/20\n",
      "0s - loss: 0.5983 - acc: 0.6875\n",
      "Epoch 17/20\n",
      "0s - loss: 0.5957 - acc: 0.6992\n",
      "Epoch 18/20\n",
      "0s - loss: 0.6001 - acc: 0.6888\n",
      "Epoch 19/20\n",
      "0s - loss: 0.5946 - acc: 0.6862\n",
      "Epoch 20/20\n",
      "0s - loss: 0.5910 - acc: 0.7031\n",
      "704/768 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bacc: 69.14%\n"
     ]
    }
   ],
   "source": [
    "# Extending the first model with activation functions\n",
    "model = Sequential()\n",
    "#specifying activation functions\n",
    "model.add(Dense(3, input_dim=8, init='uniform', activation='relu'))\n",
    "#model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, nb_epoch=20, batch_size=10,  verbose=2)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/768 [===================>..........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bacc: 69.14%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_7 (Dense)                  (None, 3)             27          dense_input_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1)             4           dense_7[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_7 [<keras.engine.topology.Node object at 0x0000016F88549128>] [<keras.engine.topology.Node object at 0x0000016F89E75C88>]\n",
      "dense_8 [<keras.engine.topology.Node object at 0x0000016F89E75C88>] []\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name, layer.inbound_nodes, layer.outbound_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.0367197 ,  0.32576466, -0.30563745],\n",
       "        [-0.03054102,  0.07326576, -0.07535113],\n",
       "        [-0.03221828, -0.09496181,  0.20233087],\n",
       "        [ 0.00759904,  0.0486616 ,  0.02355786],\n",
       "        [-0.01241106,  0.06141287,  0.03117285],\n",
       "        [-0.02536973, -0.03432333,  0.01945392],\n",
       "        [-0.04839655,  0.05393013, -0.18624373],\n",
       "        [ 0.0280936 ,  0.03104304, -0.03765763]], dtype=float32),\n",
       " array([-0.00837211, -0.3715317 ,  0.43919215], dtype=float32),\n",
       " array([[ 0.00248669],\n",
       "        [ 0.07798002],\n",
       "        [-0.15298077]], dtype=float32),\n",
       " array([-0.32388037], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-39215e1bcf97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Multilayer Perceptron\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;31m# plot graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'multilayer_perceptron_graph.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_model'"
     ]
    }
   ],
   "source": [
    "# Multilayer Perceptron\n",
    "from keras.utils import plot_model\n",
    "# plot graph\n",
    "plot_model(model, to_file='multilayer_perceptron_graph.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predictions\n",
    "predictions = model.predict(X)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(predictions)\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Keras example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains and evaluate a simple MLP on the Reuters newswire topic classification task.'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#define parameters\n",
    "max_words = 1000\n",
    "batch_size = 32\n",
    "nb_epoch = 5\n",
    "#Load data\n",
    "print('Loading data...')\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(nb_words=max_words, test_split=0.2)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "#Number of classes\n",
    "nb_classes = np.max(y_train)+1\n",
    "print(nb_classes, 'classes')\n",
    "\n",
    "#Vectorize the data\n",
    "print('Vectorizing sequence data...')\n",
    "tokenizer = Tokenizer(nb_words=max_words)\n",
    "X_train = tokenizer.sequences_to_matrix(X_train, mode='binary')\n",
    "X_test = tokenizer.sequences_to_matrix(X_test, mode='binary')\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print('Convert class vector to binary class matrix (for use with categorical_crossentropy)')\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('Y_test shape:', Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model\n",
    "print('Building model...')\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "#compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              )\n",
    "#Fit the model with the training data\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    nb_epoch=nb_epoch, batch_size=batch_size,\n",
    "                    verbose=1, validation_split=0.1)\n",
    "#evaluate the model\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
